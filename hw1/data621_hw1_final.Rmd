---
title: "Data 621 - HW1"
subtitle: "MoneyBall Predictor - Predicting The Number Of Wins"
author: JV-KN-MAR-TS
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    self_contained: false
    code_download: true
    toc_depth: 4
    df_print: paged
    code_folding: show
---


```{r library, echo=FALSE}
library(tidyverse)
library(skimr)
library(corrplot)
library(knitr)
library(kableExtra)
library(ggthemes)
library(mctest)
library(forecast)
library(MASS)

```

---

# Data Exploration

```{r datasource, echo=FALSE, message=FALSE, warning=FALSE}
# URL and CSV file names
url <- "https://raw.githubusercontent.com/Naik-Khyati/data_621/main/hw1/input/"
csv_name1 <- "moneyball-evaluation-data"
csv_name2 <- "moneyball-training-data"

# Read the CSV files into data frames
eval_dt <- read_csv(paste0(url, csv_name1, ".csv"))
train_dt <- read_csv(paste0(url, csv_name2, ".csv"))

```

---

```{r train-summary, echo=FALSE, message=FALSE, warning=FALSE}

cat("The MoneyBall training dataset contain 2276 rows and 17 columns as shown below :")

dim(train_dt)

cat("The following is a brief summary of the first 6 rows are :")

head(train_dt)

cat("The datatypes of the rows are NUMERIC as is shown below", "\n")

column_data_types <- sapply(train_dt, class)
print(column_data_types)

```

---

```{r s-stats, echo=FALSE, message=FALSE, warning=FALSE}

cat("Exploring the Summary Statistics of the Trainig Dataset", "\n")

exploration_summary <- skim(train_dt)

# Display the summary table
exploration_summary

```

---

### Density plots of variables

```{r d-plots, echo=FALSE, message=FALSE, warning=FALSE}
##
train_dt %>%
  gather(variable, value, TARGET_WINS:TEAM_FIELDING_DP) %>%
  ggplot(., aes(value)) + 
  geom_density(fill = "Blue", color="Blue") + 
  facet_wrap(~variable, scales ="free", ncol = 4) 

```

---

### Box Plots of variables

```{r bp, echo=FALSE, message=FALSE, warning=FALSE}
## Outliers

#Gather the data to create box plots with variable names on the y-axis

gathered_train_dt <- train_dt %>%
  gather(variable, value, -INDEX)

# Create the box plot with variable names on the y-axis

ggplot(gathered_train_dt, aes(x = variable, y = value)) +
  geom_boxplot() +
  labs(title = "Box Plots of Numeric Variables", y = "Variable Name") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))  # Rotate x-axis labels for readability

```

---

### Scatter Plots

```{r scat-plot, echo=FALSE, message=FALSE, warning=FALSE}
 train_dt %>% 
  gather(variable, value, -TARGET_WINS) %>%
  ggplot(., aes(value, TARGET_WINS)) + 
  geom_point(fill = "blue", color="blue") + 
  geom_smooth(method = "lm", se = FALSE, color = "black") + 
  facet_wrap(~variable, scales ="free", ncol = 4) +
  labs(x = element_blank(), y = "Wins") 

```

---

### Correlation Plot and Matrix

```{r corr-p1,echo=FALSE, message=FALSE, warning=FALSE }
temp <- train_dt  %>% 
  cor(., use = "complete.obs") #%>%
  
temp[lower.tri(temp, diag=TRUE)] <- ""
temp <- temp %>%
  as.data.frame() %>%
  rownames_to_column() %>%
  gather(Variable, Correlation, -rowname) %>%
  filter(Variable != rowname) %>%
  filter(Correlation != "") %>%
  mutate(Correlation = as.numeric(Correlation)) %>%
  rename(` Variable` = rowname) %>%
  arrange(desc(abs(Correlation))) 

  temp %>%
  filter(` Variable` == "TARGET_WINS") %>%
  kable() %>%
  kable_styling()


```

---

```{r corr-p2, echo=FALSE, message=FALSE, warning=FALSE}
## Correlation plot
# Select numeric variables for the correlation matrix
numeric_vars <- select_if(train_dt, is.numeric)

# Calculate the correlation matrix with missing values replaced by 0
correlation_matrix <- cor(numeric_vars, use = "complete.obs")  # Replace NAs with 0

# Create a heat map of the correlation matrix with a specified font
corrplot(correlation_matrix, method = "color", type = "upper", tl.cex = 0.7, tl.srt = 45)
```

---

### Analysis of Data Exploration based on above Computations :

```{r q-analysis, echo=FALSE, message=FALSE, warning=FALSE }

cat("TEAM_BATTING_HBP variable has 2,085 missing values (91.7%)")

cat("TEAM_BASERUN_CS has 772 missing values (33.9%)")

cat("TEAM_BASERUN_SB variable has 131 missing variable (5.7%)")

cat("TEAM_BATTING_SO variable has 102 missing values (4.5%)")

cat("TEAM_PITCHING_SO variable has 102 missing values (4.5%)")

cat("TEAM_FIELDING_DP variable has 286 missing values(12.5%)")

cat("TEAM_PITCHING_H has the highest mean value of 1779.21 among the 17 variables")

cat("TEAM_BASERUN_CS has the lowest mean")

cat("TEAM_PITCHING_H also has the highest median value of 1518 among the 17 variables")

cat("TEAM_BATTING_3B has the lowest median")

cat("TARGET_WINS has half of its values between 71 (25th percentile) and 92 (75th percentile)")

cat("TEAM_PITCHING_BB, TEAM_PITCHING_H and TEAM_PITCHING_SO has the largest number of outliers")

cat("TARGET_WINS has the highest positive correlation of 0.47", "\n", "with TEAM_BATTING_H, TEAM_BATTING_BB and TEAM_PITCHING_H")

cat("TARGET_WINS has the highest negative correlation of 0.39 with TEAM_FIELDING_E")

```

---

# Data Preparation 

```{r fixes,echo=FALSE, message=FALSE, warning=FALSE}

cat("Fixing the dataset deficiencies to account for missing data and outliers", "\n")

```

---

### Managing Missing Values

```{r dp-md-tb-hbp, echo=FALSE, message=FALSE, warning=FALSE}

cat("TEAM_BATTING_HBP has 91.7% of its' values missing, we will replace those with the", "\n", "MLB 2018 and 2019 averages of 65" )
train_dt <- train_dt %>% 
  mutate(TEAM_BATTING_HBP = replace_na(TEAM_BATTING_HBP,65))

```

---


```{r dp-md-tb-cs, echo=FALSE, message=FALSE, warning=FALSE}

cat("TEAM_BASERUN_CS has 33.96% of its' values missing, we will replace those with the", "\n", "MLB 2018 and 2019 averages of 30" )
train_dt <- train_dt %>% 
  mutate(TEAM_BASERUN_CS  = replace_na(TEAM_BASERUN_CS,30)) 

```

---


```{r dp-md-tb-sb, echo=FALSE, message=FALSE, warning=FALSE}

cat("TEAM_BASERUN_SB has 5.7% of its' values missing, we will replace those with the", "\n", "MEAN of the existing values" )

mean_value_sb <- mean(train_dt$TEAM_BASERUN_SB, na.rm = TRUE)

train_dt$TEAM_BASERUN_SB[is.na(train_dt$TEAM_BASERUN_SB)] <- mean_value_sb
 
```

---

```{r dp-md-tbt-so, echo=FALSE, message=FALSE, warning=FALSE}

cat("TEAM_BATTING_SO has 4.5% of its' values missing, we will replace those with the", "\n", "MEAN of the existing values" )

mean_value_sbt <- mean(train_dt$TEAM_BATTING_SO, na.rm = TRUE)

train_dt$TEAM_BATTING_SO[is.na(train_dt$TEAM_BATTING_SO)] <- mean_value_sbt
 
```

---

```{r dp-md_p-so, echo=FALSE, message=FALSE, warning=FALSE}

cat("TEAM_PITCHING_SO has 4.5% of its' values missing, we will replace those with the", "\n", "MEAN of the existing values" )

mean_value_p <- mean(train_dt$TEAM_PITCHING_SO, na.rm = TRUE)

train_dt$TEAM_PITCHING_SO[is.na(train_dt$TEAM_PITCHING_SO)] <- mean_value_p
 
```

---

```{r dp-md-f-dp, echo=FALSE, message=FALSE, warning=FALSE}

cat("TEAM_FIELDING_DP has 12.5% of its' values missing, we will replace those with the", "\n", "MEAN of the existing values" )

mean_value_f_dp <- mean(train_dt$TEAM_FIELDING_DP, na.rm = TRUE)

train_dt$TEAM_FIELDING_DP[is.na(train_dt$TEAM_FIELDING_DP)] <- mean_value_f_dp
 
```
---

### Managing Outliers

```{r outliers-1, echo=FALSE, message=FALSE, warning=FALSE}
cat("From the Data Exploration we see that the following varaibles contain Outlier Values :", "\n", "TEAM_PITCHING_SO", "\n", "TEAM_PITCHING_BB", "\n", "TEAM_PITCHING_H")

cat("We will account for these Outliers by applying defining outliers as ", "\n", "values that are more than 1.5 times the interquartile range (IQR)", "\n","below the first quartile (Q1) or above the third quartile (Q3)","\n","By performing the following computations on the dataset")

cat("Calculating first quartile (Q1) and third quartile (Q3) for each variable","\n") 

Q1_SO <- quantile(train_dt$TEAM_PITCHING_SO, 0.25)
Q3_SO <- quantile(train_dt$TEAM_PITCHING_SO, 0.75)

Q1_BB <- quantile(train_dt$TEAM_PITCHING_BB, 0.25)
Q3_BB <- quantile(train_dt$TEAM_PITCHING_BB, 0.75)

Q1_H <- quantile(train_dt$TEAM_PITCHING_H, 0.25)
Q3_H <- quantile(train_dt$TEAM_PITCHING_H, 0.75)

cat("Calculating IQR for each variable", "\n")
 
IQR_SO <- Q3_SO - Q1_SO
IQR_BB <- Q3_BB - Q1_BB
IQR_H <- Q3_H - Q1_H

cat("Setting lower and upper bounds for outliers","\n")

lower_bound_SO <- Q1_SO - 1.5 * IQR_SO
upper_bound_SO <- Q3_SO + 1.5 * IQR_SO

lower_bound_BB <- Q1_BB - 1.5 * IQR_BB
upper_bound_BB <- Q3_BB + 1.5 * IQR_BB

lower_bound_H <- Q1_H - 1.5 * IQR_H
upper_bound_H <- Q3_H + 1.5 * IQR_H

cat("Removing outliers from the dataframe","\n")

train_dt_prep1 <- train_dt %>%
  filter(
    TEAM_PITCHING_SO >= lower_bound_SO & TEAM_PITCHING_SO <= upper_bound_SO,
    TEAM_PITCHING_BB >= lower_bound_BB & TEAM_PITCHING_BB <= upper_bound_BB,
    TEAM_PITCHING_H >= lower_bound_H & TEAM_PITCHING_H <= upper_bound_H
  )

```

---

### Adding New Variables

```{r new-vars, echo=FALSE, message=FALSE, warning=FALSE}

cat("We will add to computed varaibles to enhance the model selection", "\n", "BATTING AVERAGE = TEAM_BATTING_H/(TEAM_BATTING_H + 4374 - TEAM_BASERUN_CS)")

train_dt_prep1 <- train_dt_prep1 %>%
  mutate(BATT_AVG = TEAM_BATTING_H/(TEAM_BATTING_H + 4374 - TEAM_BASERUN_CS))

cat("AND", "\n", "RUN DIFFERENTIAL = TEAM_BATTING_H + TEAM_BATTING_HR - TEAM_PITCHING_H - TEAM_PITCHING_HR")

train_dt_prep1 <- train_dt_prep1 %>%
  mutate(RUN_DIFF = TEAM_BATTING_H + TEAM_BATTING_HR - TEAM_PITCHING_H - TEAM_PITCHING_HR)

```

---

### Resultant Enhanced Dataset Overview

```{r s-stats-train-dt-prep1, echo=FALSE, message=FALSE, warning=FALSE}

cat("Exploring the Summary Statistics of the Enhanced Trainig Dataset", "\n")

exploration_summary <- skim(train_dt_prep1)

# Display the summary table
exploration_summary

```

---

### Box Plots of Enhanced Dataset :

```{r bp-train-dt-prep1, echo=FALSE, message=FALSE, warning=FALSE}
## Outliers

#Gather the data to create box plots with variable names on the y-axis

gathered_train_dt_prep1 <- train_dt_prep1 %>%
  gather(variable, value, -INDEX)

# Create the box plot with variable names on the y-axis

ggplot(gathered_train_dt_prep1, aes(x = variable, y = value)) +
  geom_boxplot() +
  labs(title = "Box Plots of Numeric Variables", y = "Variable Name") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))  # Rotate x-axis labels for readability

```

---

# Evaluation Dataset

##### Data Preparation of Eval Dataset

```{r eval_dt_summary, echo=FALSE, message=FALSE, warning=FALSE}

cat("The MoneyBall Evaluation dataset contain 256 rows and 16 columns as shown below :")

dim(eval_dt)

cat("The following is a brief summary of the first 6 rows are :")

head(eval_dt)

cat("The datatypes of the rows are NUMERIC as is shown below", "\n")

column_data_types_eval <- sapply(eval_dt, class)
print(column_data_types_eval)

cat("Exploring the Summary Statistics of the Eval Dataset", "\n")

exploration_summary_eval <- skim(eval_dt)

# Display the summary table
exploration_summary_eval

##

cat("We will replace the missing values of TEAM_BATTING_HBP the", "\n", "MLB 2018 and 2019 averages of 65" )

eval_dt <- eval_dt %>% 
  mutate(TEAM_BATTING_HBP = replace_na(TEAM_BATTING_HBP,65))

##

cat("We will replace the missing values of TEAM_BASERUN_CS", "\n", "MLB 2018 and 2019 averages of 30" )

eval_dt <- eval_dt %>% 
  mutate(TEAM_BASERUN_CS  = replace_na(TEAM_BASERUN_CS,30)) 

##

cat("We will replace the missing values of TEAM_BASERUN_SB with the", "\n", "MEAN of the existing values")

mean_value_sb_eval <- mean(eval_dt$TEAM_BASERUN_SB, na.rm = TRUE)

eval_dt$TEAM_BASERUN_SB[is.na(eval_dt$TEAM_BASERUN_SB)] <- mean_value_sb_eval

##

cat("We will replace the missing values of TEAM_BATTING_SO with the", "\n", "MEAN of the existing values")

mean_value_sbt_eval <- mean(eval_dt$TEAM_BATTING_SO, na.rm = TRUE)

eval_dt$TEAM_BATTING_SO[is.na(eval_dt$TEAM_BATTING_SO)] <- mean_value_sbt_eval

##

cat("We will replace the missing values of TEAM_PITCHING_SO with the", "\n", "MEAN of the existing values" )

mean_value_p_eval <- mean(eval_dt$TEAM_PITCHING_SO, na.rm = TRUE)

eval_dt$TEAM_PITCHING_SO[is.na(eval_dt$TEAM_PITCHING_SO)] <- mean_value_p_eval

##

cat("We will replace the missing values of TEAM_FIELDING_DP with the", "\n", "MEAN of the existing values")

mean_value_f_dp_eval <- mean(eval_dt$TEAM_FIELDING_DP, na.rm = TRUE)

eval_dt$TEAM_FIELDING_DP[is.na(eval_dt$TEAM_FIELDING_DP)] <- mean_value_f_dp_eval

##

cat("We will add to computed varaibles to enhance the model selection", "\n", "BATTING AVERAGE = TEAM_BATTING_H/(TEAM_BATTING_H + 4374 - TEAM_BASERUN_CS)")

eval_dt <- eval_dt %>%
  mutate(BATT_AVG = TEAM_BATTING_H/(TEAM_BATTING_H + 4374 - TEAM_BASERUN_CS))

##

cat("AND", "\n", "RUN DIFFERENTIAL = TEAM_BATTING_H + TEAM_BATTING_HR - TEAM_PITCHING_H - TEAM_PITCHING_HR")

eval_dt <- eval_dt %>%
  mutate(RUN_DIFF = TEAM_BATTING_H + TEAM_BATTING_HR - TEAM_PITCHING_H - TEAM_PITCHING_HR)

##

cat("Exploring the Summary Statistics of the Revised Eval Dataset", "\n")

exploration_summary_eval2 <- skim(eval_dt)

# Display the summary table
exploration_summary_eval2

##

cat("The Eval dataset is now ready to accept predictions from the Training dataset")

```

---

# Models

###### All Models Utilize the Enhanced Training Dataset

---

#### Model 1  

```{r m1, echo=FALSE, message=FALSE, warning=FALSE}

cat("Exploring a model using ONLY Predictor Variables which have a THEORETICAL NEGATIVE Impact on Wins")

m1 <-   lm(TARGET_WINS ~ TEAM_BATTING_SO + TEAM_BASERUN_CS + TEAM_FIELDING_E + TEAM_PITCHING_BB + TEAM_PITCHING_H + TEAM_PITCHING_HR, data = train_dt_prep1)

summary(m1)
cat("We see that the p-values of the 6 predictor variables have significant impact on the Target Wins", "\n", "Also, the R-Squared indicates that this model explains 17.6% of the variability in Target Wins ")

## The R-Squared value of this model is given as 

rsq_m1 <- (summary(m1)$r.squared)

## The Mean Squared Error of this model is given as

mse_m1 <- mean(summary(m1)$residuals^2)

## The F-Statistic of this model is given as

fstat_m1 <- (summary(m1)$fstatistic[1])

## The P-Value of this model is given as 

pval_m1 <- (summary(m1)$coefficients[,4])

## The degrees of freedom for this model is given as

df_m1 <- (summary(m1)$fstatistic[3])


```

---

#### Model 2 

```{r m2, echo=FALSE, message=FALSE, warning=FALSE}

cat("Exploring a model using ONLY Predictor Variables which have a THEORETICAL POSITIVE Impact on Wins")

m2 <-   lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_BATTING_HBP + TEAM_BASERUN_SB + TEAM_FIELDING_DP + TEAM_PITCHING_SO, data = train_dt_prep1)

summary(m2)

cat("We see that the p-values of the 9 predictor variables have significant impact on the Target Wins", "\n", "Also, the R-Squared indicates that this model explains 27.2% of the variability in Target Wins ")

## The R-Squared value of this model is given as 

rsq_m2 <- (summary(m2)$r.squared)

## The Mean Squared Error of this model is given as

mse_m2 <- mean(summary(m2)$residuals^2)

## The F-Statistic of this model is given as

fstat_m2 <- (summary(m2)$fstatistic[1])

## The P-Value of this model is given as 

pval_m2 <- (summary(m2)$coefficients[,4])

## The degrees of freedom for this model is given as

df_m2 <- (summary(m2)$fstatistic[3])

```

---

#### Model 3 

```{r m3, echo=FALSE, message=FALSE, warning=FALSE}

cat("Exploring a model using 11 Impactful Predictor Variables on Wins")

m3 <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_BASERUN_SB + TEAM_BATTING_HBP + TEAM_PITCHING_SO + TEAM_BATTING_SO +TEAM_FIELDING_DP+TEAM_FIELDING_E, data = train_dt_prep1)

summary(m3)

cat("We see that the p-values of the 11 predictor variables have significant impact on the Target Wins", "\n", "Also, the R-Squared indicates that this model explains 36.2% of the variability in Target Wins ")

## The R-Squared value of this model is given as 

rsq_m3 <- (summary(m3)$r.squared)

## The Mean Squared Error of this model is given as

mse_m3 <- mean(summary(m3)$residuals^2)

## The F-Statistic of this model is given as

fstat_m3 <- (summary(m3)$fstatistic[1])

## The P-Value of this model is given as 

pval_m3 <- (summary(m3)$coefficients[,4])

## The degrees of freedom for this model is given as

df_m3 <- (summary(m3)$fstatistic[3])

```

---

#### Model 4 

```{r m4, echo=FALSE, message=FALSE, warning=FALSE}

cat("Exploring a model using 13 Impactful Predictor Variables on Wins")

m4 <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_BASERUN_SB + TEAM_BATTING_HBP + TEAM_PITCHING_SO +TEAM_PITCHING_BB+TEAM_PITCHING_H+ TEAM_BATTING_SO +TEAM_FIELDING_DP+TEAM_FIELDING_E, data = train_dt_prep1)

summary(m4)

cat("We see that the p-values of the 13 predictor variables have significant impact on the Target Wins", "\n", "Also the R-Squared indicates that this model explains 38.2% of the variability in Target Wins ")

## The R-Squared value of this model is given as 

rsq_m4 <- (summary(m4)$r.squared)

## The Mean Squared Error of this model is given as

mse_m4 <- mean(summary(m4)$residuals^2)

## The F-Statistic of this model is given as

fstat_m4 <- (summary(m4)$fstatistic[1])

## The P-Value of this model is given as 

pval_m4 <- (summary(m4)$coefficients[,4])

## The degrees of freedom for this model is given as

df_m4 <- (summary(m4)$fstatistic[3])

```

---

#### Model 5

###### This Model Examines the entire Training Dataset
###### Examining Model Fit and Effects of MultiCollinearity

```{r m5, echo=FALSE, message=FALSE, warning=FALSE}

cat("Exploring a model using ALL Predictor Variables on Wins")

cat("Checking the structure of the dataset","\n")

cat("Dropping the 'INDEX' variable")

train_dt_prep2 <- subset(train_dt_prep1, select = -c(INDEX,TARGET_WINS))

str(train_dt_prep2)

dim(train_dt_prep2)

summary(train_dt_prep2)

train_dt_prep2[!complete.cases(train_dt_prep2),]

cat("The Predictor Variables included in the Model 5 V1 Regression are : ", "\n")

sort(colnames(train_dt_prep2))

```

---

```{r model5_v1_v2, echo=FALSE, message=FALSE, warning=FALSE}

model5_f1 <- as.formula(paste("TARGET_WINS", "~",
        paste(sort(colnames(train_dt_prep2)), collapse = "+"),
        sep = ""
    ))

cat("The formula for regression m5_v1 is :","\n")

model5_f1

lm_m5_v1 <- lm((model5_f1),data = train_dt_prep1 )

summary(lm_m5_v1)

##########################

## The R-Squared value of this model is given as 

rsq_lm_m5_v1 <- (summary(lm_m5_v1)$r.squared)

## The Mean Squared Error of this model is given as

mse_lm_m5_v1 <- mean(summary(lm_m5_v1)$residuals^2)

## The F-Statistic of this model is given as

fstat_lm_m5_v1 <- (summary(lm_m5_v1)$fstatistic[1])

## The P-Value of this model is given as 

pval_lm_m5_v1 <- (summary(lm_m5_v1)$coefficients[,4])

## The degrees of freedom for this model is given as

df_lm_m5_v1 <- (summary(lm_m5_v1)$fstatistic[3])

#########################

cat("Dropping the undefined variable **TEAM_PITCHING_HR**","\n", 
"We are dropping this predictor variable since the model residuals is indicating", "\n",
"that it is identical to another predictor or it is","\n",
"perfectly predicted by the combination of the other two predictors")

train_dt_prep3 <- subset(train_dt_prep2, select = -c(TEAM_PITCHING_HR))

cat("The resulting dataset set is","\n")

sort(colnames(train_dt_prep3))

cat("The formula for regression v2 after removing the undefined variable is","\n")

model5_f2 <- as.formula(paste("TARGET_WINS", "~",
        paste(sort(colnames(train_dt_prep3)), collapse = "+"),
        sep = ""
    ))

model5_f2

cat("The regression model is now shown as", "\n")

lm_m5_v2 <- lm((model5_f2),data = train_dt_prep1 )

summary(lm_m5_v2)

###############

## The R-Squared value of this model is given as 

rsq_lm_m5_v2 <- (summary(lm_m5_v2)$r.squared)

## The Mean Squared Error of this model is given as

mse_lm_m5_v2 <- mean(summary(lm_m5_v2)$residuals^2)

## The F-Statistic of this model (M1) is given as

fstat_lm_m5_v2 <- (summary(lm_m5_v2)$fstatistic[1])

## The P-Value of this model is given as 

pval_lm_m5_v2 <- (summary(lm_m5_v2)$coefficients[,4])

## The degrees of freedom for this model is given as

df_lm_m5_v2 <- (summary(lm_m5_v2)$fstatistic[3])

###############

cat("We see that the p-values of the model using all valid predictor variables have significant", "\n",
"impact on the Target Wins", "\n",
"Also, the R-Squared indicates that this model explains 40.1% of the variability in Target Wins","\n",
"This R-Squared values is not significantly improved from Models", "\n",
"M2 (27.2%), M3 (36.2%), M4 (38.2%) and M5v1 (40.1%)")

```

---

###### Testing for Multicollinearity

```{r vif, echo=FALSE, message=TRUE, warning=FALSE}


cat("-----VIF Scoring-----")

cat("Multicollinearity occurs when two or more predictor variables", "\n", 
"are highly correlated to each other, such that they do not provide unique", "\n",
"or independent information in the regression model.", "\n", 
"If the degree of correlation is high enough between variables,", "\n",
"it can cause problems when fitting and interpreting the regression model.")

cat("To test this model for Multicollinearity we will employ the", "\n", 
"imcdiag function from the 'mctest' library and examine the", "\n",
"Variance Inflation Factor (VIF) score", "\n",
"Note : Scores over 5 are moderately multicollinear. Scores over 10 are very problematic")

imcdiag(lm_m5_v2)

```

---


```{r c_mc, echo=FALSE, message=FALSE, warning=FALSE}

cat("FIXING MULTICOLLINEARITY")

cat("We will remove the fields from the Regression Model that caused MultiCollinearity")

train_dt_prep4 <- subset(train_dt_prep3, select = -c(BATT_AVG, RUN_DIFF, TEAM_BATTING_BB, TEAM_BATTING_H, TEAM_BATTING_SO, TEAM_PITCHING_BB, TEAM_PITCHING_H, TEAM_PITCHING_SO ))

cat("The resulting dataset set is","\n")

sort(colnames(train_dt_prep4))

cat("The formula for regression v3 after removing the MultiCollinear variables is","\n")

model5_f3 <- as.formula(paste("TARGET_WINS", "~",
        paste(sort(colnames(train_dt_prep4)), collapse = "+"),
        sep = ""
    ))

model5_f3

cat("The regression model is now shown as", "\n")

lm_m5_v3 <- lm((model5_f3),data = train_dt_prep1 )

summary(lm_m5_v3)

#############################

## The R-Squared value of this model is given as 

rsq_lm_m5_v3 <- (summary(lm_m5_v3)$r.squared)

## The Mean Squared Error of this model is given as

mse_lm_m5_v3 <- mean(summary(lm_m5_v3)$residuals^2)

## The F-Statistic of this model (M1) is given as

fstat_lm_m5_v3 <- (summary(lm_m5_v3)$fstatistic[1])

## The P-Value of this model is given as 

pval_lm_m5_v3 <- (summary(lm_m5_v3)$coefficients[,4])

## The degrees of freedom for this model is given as

df_lm_m5_v3 <- (summary(lm_m5_v3)$fstatistic[3])

###############################


cat("VIF Scoring for Model V3")

imcdiag(lm_m5_v3)

cat("NOTE : THE VIF SCORES FOR MODEL5V3 ARE WELL WITHIN THE RANGES FOR NO", "\n",
    "MULTICOLLINEARITY EFFECTS", "\n",
    "THIS MODEL PERFORMS WITH A R-SQUARED OF ONLY 28.2%", "\n",
    "THIS IS NOT THE OPTIMAL MODEL AMONG THE MODELS IN THIS PROJECT")

```

---

# Model Selection and Predictions
#### Model Selection

```{r ms, echo=FALSE, message=FALSE, warning=FALSE}

cat("Our model selection discussion include the following coefficients for each of the 7 models created")

cat("The coefficients are : R-Squared, Mean Squared Error, F-Statistic, Degrees of Freedom", "\n")

cat("R-Squared is a statistical measure that indicates how much of the variation of a dependent", "\n",
    "variable is explained by an independent variable in a regression mode", "\n",
    "Typically the higher the R-Squared (50%-90%)  the better the correlation and fit of the model", "\n",
    " This is a general rule of thumb, the acceptable value is subject to the dataset being examined")

cat("The Mean Squared Error measures how close a regression line is to a set of data points", "\n",
    "There is no correct value for MSE. Simply put, the lower the value the better and 0 means", "\n",
    "the model is perfect")

cat("F-statistic, also known as F-value is used in regression analysis to identify the means", "\n",
"between two populations are significantly different or not","\n",
"The higher the F value, the better the model")

cat("Degrees of freedom are the number of independent variables that can be estimated", "\n",
"in a statistical analysis and tell you how many items can be randomly selected before", "\n",
"constraints must be put in place", "\n",
"A higher degree of freedom means more power to reject a false null hypothesis", "\n",
"and find a significant result")

```

---

##### Tabulating the Coefficients of the Regression Models

```{r ms2, echo=TRUE, message=FALSE, warning=FALSE}

## Tabulating coefficients from each regression model

data= matrix(c(1:28), ncol=4, byrow=TRUE)

colnames(data) = c('R-Squared','Mean-Sq-Error','F-Statistic','Degrees-Freedom')
rownames(data) <- c('Model-1','Model-2','Model-3','Model-4','Model-5-1','Model-5-2','Model-5-3')
mmatrix=as.data.frame(data)

## R-Squared

mmatrix[1,1] = rsq_m1
mmatrix[2,1] = rsq_m2
mmatrix[3,1] = rsq_m3
mmatrix[4,1] = rsq_m4
mmatrix[5,1] = rsq_lm_m5_v1
mmatrix[6,1] = rsq_lm_m5_v2
mmatrix[7,1] = rsq_lm_m5_v3

## Mean-Sq-Error

mmatrix[1,2] = mse_m1
mmatrix[2,2] = mse_m2
mmatrix[3,2] = mse_m3
mmatrix[4,2] = mse_m4
mmatrix[5,2] = mse_lm_m5_v1
mmatrix[6,2] = mse_lm_m5_v2
mmatrix[7,2] = mse_lm_m5_v3

## F-Statistic

mmatrix[1,3] = fstat_m1
mmatrix[2,3] = fstat_m2
mmatrix[3,3] = fstat_m3
mmatrix[4,3] = fstat_m4
mmatrix[5,3] = fstat_lm_m5_v1
mmatrix[6,3] = fstat_lm_m5_v2
mmatrix[7,3] = fstat_lm_m5_v3

## Degrees-Freedom

mmatrix[1,3] = df_m1
mmatrix[2,3] = df_m2
mmatrix[3,3] = df_m3
mmatrix[4,3] = df_m4
mmatrix[5,3] = df_lm_m5_v1
mmatrix[6,3] = df_lm_m5_v2
mmatrix[7,3] = df_lm_m5_v3

mmatrix

```

---

##### Our Selected Model

```{r qualitative, echo=FALSE, message=FALSE, warning=FALSE}

cat("We Examined a total of 7 models")

cat("Our focus on models 5-1, 5-2, 5-3 was primarily to discuss the possible", "\n",
    "effects of MultiCollinearity between the predictor variables")

cat("As is shown in the table, models 5-1 and 5-2 have similar proeperities", "\n",
    "since the difference is that model5-2 removes the one variable not defined")

cat("This omission can be seen in the increase of the Degrees of Freem in", "\n",
    "model 5-2 over 5-1, their R-Squared remain the sample")

cat("Model 5-3 is a result of ommitting the recommended variables based", "\n", 
    "on the VIF scres, this significantly decreased the R-Squared value of", "\n",
    "the model but increased the Degrees of Freedom to the highest calues of all the models")

cat("We selected to Reommend Model 4, we think that this model best fits the training", "\n",
    "dataset and will be the most effective predictor of the Evaluation dataset")

```

---

### Applying Model 4 to the Evaluation Dataset
##### We demonstrated the Prediction using multiple models

```{r model_predictions, echo=FALSE, message=FALSE, warning=FALSE}

cat("Model m1 Predictions")

prediction_m1 <- predict(m1,eval_dt, type = "response")

head(prediction_m1)

##

cat("Model m2 Predictions")

prediction_m2 <- predict(m2,eval_dt, type = "response")

head(prediction_m2)

##

cat("Model m3 Predictions")

prediction_m3 <- predict(m3,eval_dt, type = "response")

head(prediction_m3)

##

cat("Model lm_m5_v2 Predictions")

prediction_lm_m5_v2 <- predict(lm_m5_v2,eval_dt, type = "response")

head(prediction_lm_m5_v2)

cat("----------     OUR PREFERRED MODEL     -----------")

cat("Model m4 Predictions")

prediction_m4 <- predict(m4,eval_dt, type = "response")

head(prediction_m4)

exploration_summary_prediction_M4 <- skim(prediction_m4)

# Display the summary table
exploration_summary_prediction_M4

```

---

# Appendix

### Program Code

---

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```

---

# References

https://mathworld.wolfram.com/ExponentialSumFormulas.html


https://pubs.wsb.wisc.edu/academics/analytics-using-r-2019/gamma-variables-optional.html


https://www.programmingr.com/examples/neat-tricks/sample-r-function/rexp/


https://bookdown.org/rdpeng/rprogdatascience/simulation.html


https://math.stackexchange.com/questions/2189317/mean-of-gamma-distribution


https://www.youtube.com/watch?v=cI-WFRqXbKM